################################################################################
# Host-specific Peel configuration
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# Customize Peel configuration values appearing in
#
#   https://github.com/stratosphere/peel/blob/master/peel-core/src/main/resources/reference.peel.conf
#
# here.
#

# include environment hosts lists
include "hosts.conf"

app {
    # custom bundle paths
    path {
        # global data repository
        datarepository = "/data/datasets"
        # shared downloads path
        downloads = "/home/hadoop/Downloads/systems"
        # shared systems path
        systems = "/share/hadoop/peel/systems"
    }
}

system {
    default {
        # user & group on this environment
        user = ${user.name}
        group = "hadoop"
        config {
            masters = ["cloud-11"]
            slaves = ["cloud-11"]
            java = {
                home = "/usr/lib/jvm/java-8-oracle"
            }
        }
    }
  flink {
    config {
      yaml {
        jobmanager.rpc.address = ${runtime.hostname}
        taskmanager.heap.size = 24576mb
        jobmanager.heap.size = 1024mb
        taskmanager.network.memory.max = 2048mb # E2Data k-means fails with default value because of too few network buffers
        env.hadoop.conf.dir = ${system.hadoop-3.path.config}
        # taskmanager.tmp.dirs = "/data/1/peel/flink/tmp:/data/2/peel/flink/tmp:/data/3/peel/flink/tmp:/data/4/peel/flink/tmp"
      }
    }
  }
  hadoop-3 {
    config {
      core {
        fs.default.name = "hdfs://"${runtime.hostname}":9000"
      }
      capacity-scheduler {
        yarn.scheduler.capacity.resource-calculator = org.apache.hadoop.yarn.util.resource.DominantResourceCalculator
      }
      hdfs {
          dfs.namenode.name.dir = "/data/1/peel/hadoop-2/name,/data/2/peel/hadoop-2/name,/data/3/peel/hadoop-2/name,/data/4/peel/hadoop-2/name"
          dfs.datanode.data.dir = "/data/1/peel/hadoop-2/data,/data/2/peel/hadoop-2/data,/data/3/peel/hadoop-2/name,/data/4/peel/hadoop-2/data"
          dfs.namenode.checkpoint.dir = "/data/1/peel/hadoop-2/check,/data/2/peel/hadoop-2/check,/data/3/peel/hadoop-2/name,/data/4/peel/hadoop-2/check"
      }
      yarn {
        yarn.scheduler.maximum-allocation-vcores = 16
        yarn.scheduler.maximum-allocation-mb = 24576
        yarn.scheduler.minimim-allocation-mb = 256
        yarn.resourcemanager.hostname = ${runtime.hostname}
        yarn.nodemanager.resource.memory-mb = 25600 # = 24576 + 1024
        yarn.nodemanager.resource.cpu-vcores = 17
        yarn.nodemanager.vmem-pmem-ratio = "4"
        yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage = 98
      }
    }
  }
}
